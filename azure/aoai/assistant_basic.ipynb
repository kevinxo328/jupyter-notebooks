{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "- openai （需要 1.x 版）\n",
    "- Azure OpenAI 助理目前位於瑞典中部、美國東部 2 和澳大利亞東部。 如需這些區域中模型可用性的詳細資訊，請參閱 [模型指南](https://learn.microsoft.com/zh-tw/azure/ai-services/openai/concepts/models#assistants-preview)\n",
    "- API Version 在 2024-02-15-preview 之後\n",
    "- 模型：`gpt-35-turbo (1106)` 或 `gpt-4 (1106-preview)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_settings import BaseSettings\n",
    "from typing import Optional\n",
    "\n",
    "class BingSearchSettings(BaseSettings):\n",
    "    BING_SEARCH_API_KEY: str\n",
    "    BING_SEACH_API_ENDPOINT: str = \"https://api.bing.microsoft.com/v7.0/search\"\n",
    "\n",
    "\n",
    "class AOAISettings(BaseSettings):\n",
    "    AOAI_API_KEY: str\n",
    "    AOAI_API_VERSION: str\n",
    "    AOAI_API_ENDPOINT: str\n",
    "    AOAI_GPT3_MODEL: str\n",
    "    AOAI_GPT4_MODEL: Optional[str] = \"\"\n",
    "    AOAI_EMBEDDING_MODEL: str\n",
    "\n",
    "\n",
    "class Env(AOAISettings, BingSearchSettings):\n",
    "    class Config:\n",
    "        env_file = \".env\"\n",
    "\n",
    "env = Env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "aoai = AzureOpenAI(\n",
    "    api_key=env.AOAI_API_KEY,\n",
    "    api_version='2024-02-15-preview',\n",
    "    azure_endpoint=env.AOAI_API_ENDPOINT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "def poll_run_till_completion(\n",
    "    client: AzureOpenAI,\n",
    "    thread_id: str,\n",
    "    run_id: str,\n",
    "    available_functions: dict,\n",
    "    verbose: bool,\n",
    "    max_steps: int = 10,\n",
    "    wait: int = 3,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Poll a run until it is completed or failed or exceeds a certain number of iterations (MAX_STEPS)\n",
    "    with a preset wait in between polls\n",
    "\n",
    "    @param client: OpenAI client\n",
    "    @param thread_id: Thread ID\n",
    "    @param run_id: Run ID\n",
    "    @param assistant_id: Assistant ID\n",
    "    @param verbose: Print verbose output\n",
    "    @param max_steps: Maximum number of steps to poll\n",
    "    @param wait: Wait time in seconds between polls\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if (client is None and thread_id is None) or run_id is None:\n",
    "        print(\"Client, Thread ID and Run ID are required.\")\n",
    "        return\n",
    "    try:\n",
    "        cnt = 0\n",
    "        while cnt < max_steps:\n",
    "            run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)\n",
    "            if verbose:\n",
    "                print(\"Poll {}: {}\".format(cnt, run.status))\n",
    "            cnt += 1\n",
    "            \n",
    "            # 需要呼叫外部工具\n",
    "            if run.status == \"requires_action\":\n",
    "                tool_responses = []\n",
    "                if (\n",
    "                    run.required_action is not None and\n",
    "                    run.required_action.type == \"submit_tool_outputs\"\n",
    "                    and run.required_action.submit_tool_outputs.tool_calls is not None\n",
    "                ):\n",
    "                    tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "\n",
    "                    for call in tool_calls:\n",
    "                        if call.type == \"function\":\n",
    "                            if call.function.name not in available_functions:\n",
    "                                raise Exception(\"Function requested by the model does not exist\")\n",
    "                            function_to_call = available_functions[call.function.name]\n",
    "                            tool_response = function_to_call(**json.loads(call.function.arguments))\n",
    "                            tool_responses.append({\"tool_call_id\": call.id, \"output\": tool_response if isinstance(tool_response, str) else json.dumps(tool_response)})\n",
    "\n",
    "                run = client.beta.threads.runs.submit_tool_outputs(\n",
    "                    thread_id=thread_id, run_id=run.id, tool_outputs=tool_responses\n",
    "                )\n",
    "            if run.status == \"failed\":\n",
    "                print(\"Run failed.\")\n",
    "                break\n",
    "            if run.status == \"completed\":\n",
    "                break\n",
    "            time.sleep(wait)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "def retrieve_and_print_messages(\n",
    "    client: AzureOpenAI, thread_id: str, verbose: bool, out_dir: Optional[str] = None\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Retrieve a list of messages in a thread and print it out with the query and response\n",
    "\n",
    "    @param client: OpenAI client\n",
    "    @param thread_id: Thread ID\n",
    "    @param verbose: Print verbose output\n",
    "    @param out_dir: Output directory to save images\n",
    "    @return: Messages object\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if client is None and thread_id is None:\n",
    "        print(\"Client and Thread ID are required.\")\n",
    "        return None\n",
    "    try:\n",
    "        messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "        display_role = {\"user\": \"User: \", \"assistant\": \"Assistant: \"}\n",
    "\n",
    "        # prev_role = None\n",
    "\n",
    "        # if verbose:\n",
    "            # print(\"\\n\\nCONVERSATION:\")\n",
    "\n",
    "        qa = []\n",
    "\n",
    "        for message in messages.data:\n",
    "            if message.role == \"assistant\":\n",
    "                qa.append(message)\n",
    "            if message.role == \"user\":\n",
    "                qa.append(message)\n",
    "                break\n",
    "\n",
    "        for md in reversed(qa):\n",
    "            # if prev_role == \"assistant\" and md.role == \"user\" and verbose:\n",
    "                # print(\"------ \\n\")\n",
    "\n",
    "            for mc in md.content:\n",
    "                # Check if valid text field is present in the mc object\n",
    "                if mc.type == \"text\":\n",
    "                    txt_val = mc.text.value\n",
    "                # Check if valid image field is present in the mc object\n",
    "                elif mc.type == \"image_file\":\n",
    "                    image_data = client.files.content(mc.image_file.file_id)\n",
    "                    if out_dir is not None:\n",
    "                        out_dir_path = Path(out_dir)\n",
    "                        if out_dir_path.exists():\n",
    "                            image_path = out_dir_path / (mc.image_file.file_id + \".png\")\n",
    "                            with image_path.open(\"wb\") as f:\n",
    "                                f.write(image_data.read())\n",
    "\n",
    "                if verbose:\n",
    "                    # if prev_role == md.role:\n",
    "                        # print(txt_val)\n",
    "                    # else:\n",
    "                    print(\"{}:\\n{}\".format(display_role[md.role], txt_val))\n",
    "            # prev_role = md.role\n",
    "        print(\"=\" * 100)\n",
    "        return messages\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.assistant import Assistant\n",
    "from typing import Iterable\n",
    "from openai.types.beta import AssistantToolParam\n",
    "\n",
    "\n",
    "def create_assistant(aoai: AzureOpenAI, name:str, instructions:str, model: str = env.AOAI_GPT4_MODEL if env.AOAI_GPT4_MODEL else env.AOAI_GPT3_MODEL, tools: Iterable[AssistantToolParam] = []) -> Assistant:\n",
    "    return aoai.beta.assistants.create(name=name, instructions=instructions, model=model, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.assistant import Assistant\n",
    "from time import sleep\n",
    "\n",
    "def chat_with_assistant(assistant: Assistant, aoai: AzureOpenAI, available_functions: dict = {}, verbose: bool = False):\n",
    "    \"\"\"\n",
    "    Chat with the assistant\n",
    "\n",
    "    @param assistant: Assistant object\n",
    "    @param aoai: OpenAI client\n",
    "    @param available_functions: Dictionary of available functions\n",
    "    @param verbose: Print verbose output\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if assistant is None:\n",
    "        print(\"Assistant is required.\")\n",
    "        return\n",
    "    \n",
    "    if aoai is None:\n",
    "        print(\"OpenAI client is required.\")\n",
    "        return\n",
    "        \n",
    "    # Create a thread\n",
    "    thread = aoai.beta.threads.create()\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input == \"exit\":\n",
    "            break\n",
    "\n",
    "        aoai.beta.threads.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=user_input,\n",
    "        )\n",
    "\n",
    "\n",
    "        # Run the thread\n",
    "        run = aoai.beta.threads.runs.create(\n",
    "            thread_id=thread.id,\n",
    "            assistant_id=assistant.id,\n",
    "        )\n",
    "\n",
    "        # Retrieve the status of the run\n",
    "        start_time = time.perf_counter()\n",
    "        poll_run_till_completion(\n",
    "            client=aoai,\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "            available_functions=available_functions,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        end_time = time.perf_counter()\n",
    "        if verbose:\n",
    "            print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "        # Retrieve and print messages\n",
    "        retrieve_and_print_messages(client=aoai, thread_id=thread.id, verbose=verbose)\n",
    "\n",
    "        sleep(2)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Interceptor\n",
    "- [Reference](https://learn.microsoft.com/zh-tw/azure/ai-services/openai/how-to/code-interpreter?tabs=python)\n",
    "- 需要額外的 [Pricing](https://azure.microsoft.com/zh-tw/pricing/details/cognitive-services/openai-service/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "from openai.types.beta import AssistantToolParam\n",
    "\n",
    "\n",
    "def create_math_assistant(\n",
    "    model: str = env.AOAI_GPT4_MODEL if env.AOAI_GPT4_MODEL else env.AOAI_GPT3_MODEL,\n",
    "):\n",
    "    name = \"Math Assist\"\n",
    "    instructions = (\n",
    "        \"You are an AI assistant that can write code to help answer math questions.\"\n",
    "    )\n",
    "    tools: Iterable[AssistantToolParam] = [{\"type\": \"code_interpreter\"}]\n",
    "\n",
    "    return create_assistant(aoai, name, instructions, tools=tools, model=model)\n",
    "\n",
    "\n",
    "def chat_with_math_assistant(\n",
    "    aoai: AzureOpenAI,\n",
    "    model: str = env.AOAI_GPT4_MODEL if env.AOAI_GPT4_MODEL else env.AOAI_GPT3_MODEL,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    assistant = create_math_assistant(model=model)\n",
    "    chat_with_assistant(aoai=aoai, assistant=assistant, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assistant Function Calling with Bing Search\n",
    "\n",
    "- [Reference](https://github.com/Azure-Samples/azureai-samples/blob/main/scenarios/Assistants/function_calling/assistants_function_calling_with_bing_search.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "import requests\n",
    "from openai.types.beta import AssistantToolParam\n",
    "\n",
    "def bing_search(query:str)->list:\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": env.BING_SEARCH_API_KEY}\n",
    "    params = {\"q\": query, \"textDecorations\": False}\n",
    "    response = requests.get(env.BING_SEACH_API_ENDPOINT, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    search_results = response.json()\n",
    "\n",
    "    output = []\n",
    "\n",
    "    for result in search_results[\"webPages\"][\"value\"]:\n",
    "        output.append({\"title\": result[\"name\"], \"link\": result[\"url\"], \"snippet\": result[\"snippet\"]})\n",
    "\n",
    "    return output\n",
    "\n",
    "def create_bing_search_assistant(\n",
    "    model: str = env.AOAI_GPT4_MODEL if env.AOAI_GPT4_MODEL else env.AOAI_GPT3_MODEL,\n",
    "):\n",
    "    name = \"Bing Search Assist\"\n",
    "\n",
    "    instructions = \"\"\"You are an assistant designed to help people answer questions.\n",
    "\n",
    "    You have access to query the web using Bing Search. You should call bing search whenever a question requires up to date information or could benefit from web data.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    tools:Iterable[AssistantToolParam] = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"search_bing\",\n",
    "                \"description\": \"Searches bing to get up-to-date information from the web.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The search query\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"query\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return create_assistant(aoai, name, instructions, tools=tools, model=model)\n",
    "\n",
    "def chat_with_bing_search_assistant(\n",
    "    aoai: AzureOpenAI,\n",
    "    model: str = env.AOAI_GPT4_MODEL if env.AOAI_GPT4_MODEL else env.AOAI_GPT3_MODEL,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    assistant = create_bing_search_assistant(model=model)\n",
    "    chat_with_assistant(aoai=aoai, assistant=assistant, available_functions={\"search_bing\": bing_search}, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Agent\n",
    "- [Reference](https://github.com/Azure-Samples/azureai-samples/tree/main/scenarios/Assistants/multi-agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta import Assistant, AssistantToolParam\n",
    "\n",
    "def create_proxy_agent(\n",
    "    assistants: list[Assistant],\n",
    "    model: str = env.AOAI_GPT4_MODEL if env.AOAI_GPT4_MODEL else env.AOAI_GPT3_MODEL,\n",
    "):\n",
    "    \"\"\"\n",
    "    This agent facilitates the conversation between the user and other agents, ensuring successful completion of the task.\n",
    "    \"\"\"\n",
    "\n",
    "    name = \"Proxy Agent\"\n",
    "    instructions = f\"You are an AI assistant that can help users answer questions using {', '.join([assistant.name.__str__() for assistant in assistants])}.\"\n",
    "\n",
    "    tools: Iterable[AssistantToolParam] = []\n",
    "    has_code_interpreter = False\n",
    "    for assistant in assistants:\n",
    "        for tool in assistant.tools:\n",
    "            if tool.type == \"function\":\n",
    "                tools.append(\n",
    "                    {\n",
    "                        \"type\": \"function\",\n",
    "                        \"function\": tool.model_dump(mode=\"json\")[\"function\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            if tool.type == \"code_interpreter\" and not has_code_interpreter:\n",
    "                has_code_interpreter = True\n",
    "                tools.append({\"type\": \"code_interpreter\"})\n",
    "\n",
    "    return create_assistant(aoai, name, instructions, tools=tools, model=model)\n",
    "\n",
    "\n",
    "def chat_with_proxy_assistant(\n",
    "    aoai: AzureOpenAI,\n",
    "    assistants: list[Assistant],\n",
    "    model: str = env.AOAI_GPT4_MODEL if env.AOAI_GPT4_MODEL else env.AOAI_GPT3_MODEL,\n",
    "    available_functions: dict = {},\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    assistant = create_proxy_agent(assistants=assistants, model=model)\n",
    "    chat_with_assistant(assistant, aoai, verbose=verbose, available_functions=available_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poll 0: queued\n",
      "Poll 1: in_progress\n",
      "Poll 2: completed\n",
      "Time taken: 7.14 seconds\n",
      "User: :\n",
      "Ali’s class has a capacity of 120 students.  Each of John’s classes has a capacity of 120/8 = 15 students.  The total capacity of John’s two classes is?\n",
      "Assistant: :\n",
      "The total capacity of John's two classes can be calculated by multiplying the capacity of each class by the number of classes. Since each of John's classes has a capacity of 15 students, and he has two classes, the total capacity is:\n",
      "\n",
      "Total capacity = (Capacity of 1 class) x (Number of classes)\n",
      "\n",
      "Let's calculate it.\n",
      "Assistant: :\n",
      "The total capacity of John's two classes is 30 students.\n",
      "====================================================================================================\n",
      "Poll 0: queued\n",
      "Poll 1: completed\n",
      "Time taken: 3.74 seconds\n",
      "User: :\n",
      "最近台北市有什麼新聞？\n",
      "Assistant: :\n",
      "很抱歉，由於這個環境被禁用了網絡訪問功能，所以無法提供即時的新聞。建議您使用網絡訪問功能來瀏覽台北市的新聞網站或者使用新聞應用程序來獲取最新的新聞資訊。\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "chat_with_math_assistant(aoai, verbose=True, model=env.AOAI_GPT3_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poll 0: queued\n",
      "Poll 1: completed\n",
      "Time taken: 3.74 seconds\n",
      "User: :\n",
      "Ali’s class has a capacity of 120 students.  Each of John’s classes has a capacity of 120/8 = 15 students.  The total capacity of John’s two classes is?\n",
      "Assistant: :\n",
      "John's class has a capacity of 15 students. Since John has two classes, the total capacity of John's two classes is 15 * 2 = 30 students.\n",
      "====================================================================================================\n",
      "Poll 0: in_progress\n",
      "Poll 1: requires_action\n",
      "Poll 2: in_progress\n",
      "Poll 3: in_progress\n",
      "Poll 4: in_progress\n",
      "Poll 5: completed\n",
      "Time taken: 19.05 seconds\n",
      "User: :\n",
      "最近台北市有什麼新聞？\n",
      "Assistant: :\n",
      "根據最新的資料，台北市的新聞包括：\n",
      "\n",
      "1. 《自由時報》報導稱「台灣自古屬中國」王定宇稱「古态阿儸」：唬爛就是唬爛。過去吸蟹區縣市府還大使北市10大奙音車投訴熱點未設定固定式燈照相... (來源: [自由時報 - 即時 - 自由電子報](https://news.ltn.com.tw/list/breakingnews/Taipei))\n",
      "\n",
      "2. 《聯合報》報導稱台北市今天下午大雷雨，其中最大雨量為大安區台灣大學站，時雨量約50.5毫米。台北市災防截圖顯示，昨天的降雨量約30分，也接報4件積水通報，其中建高一度洪水...(來源: [聯合新聞網](https://udn.com/news/story/7323/8038970))\n",
      "\n",
      "3. 《自由時報》報導稱台北市政府5月初通過的「台北市興岩社福大業」由台北市社會局主導、新工處代辦工程，昨天的短期豪降雨，C杆頂樓排水不及，結果陽台間小雨、電梯笥水... (來源: [自由時報 - 大台北 - 自由電子報](https://news.ltn.com.tw/news/Taipei/breakingnews/4709317))\n",
      "\n",
      "4. 《自由時報》報導稱《自由爆新聞》304萬支持者逃離藍白？！最新民調震人變化，根據最新民調，304萬支持者逃離藍白陣營，這是台北市的最新民...(來源: [自由時報 - 大台北 - 自由電子報](https://news.ltn.com.tw/news/Taipei/breakingnews/4709483))\n",
      "\n",
      "以上是一些最新的台北市新聞報導，您可以點擊連結查看詳細內容。\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "chat_with_bing_search_assistant(aoai, verbose=True, model=env.AOAI_GPT3_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poll 0: queued\n",
      "Poll 1: in_progress\n",
      "Poll 2: in_progress\n",
      "Poll 3: in_progress\n",
      "Poll 4: completed\n",
      "Time taken: 13.83 seconds\n",
      "User: :\n",
      "Ali’s class has a capacity of 120 students.  Each of John’s classes has a capacity of 120/8 = 15 students.  The total capacity of John’s two classes is?\n",
      "Assistant: :\n",
      "The total capacity of John's two classes is 30 students.\n",
      "====================================================================================================\n",
      "Poll 0: queued\n",
      "Poll 1: requires_action\n",
      "Poll 2: in_progress\n",
      "Poll 3: completed\n",
      "Time taken: 11.94 seconds\n",
      "User: :\n",
      "最近台北市有什麼新聞？\n",
      "Assistant: :\n",
      "抱歉，我無法直接提供最新的台北市新聞。您可以使用網上新聞網站或新聞應用程式來瞭解台北市的最新新聞。常見的新聞網站和應用程式包括自由時報、中央社、蘋果日報和Yahoo新聞等。您可以在這些平台上搜尋「台北市最新新聞」以獲取最新的新聞資訊。\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "math_assistant = create_math_assistant(env.AOAI_GPT3_MODEL)\n",
    "bing_search_assistant = create_bing_search_assistant(env.AOAI_GPT3_MODEL)\n",
    "available_functions = {\"search_bing\": bing_search}\n",
    "\n",
    "chat_with_proxy_assistant(aoai, verbose=True, model=env.AOAI_GPT3_MODEL, assistants=[math_assistant, bing_search_assistant], available_functions=available_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
